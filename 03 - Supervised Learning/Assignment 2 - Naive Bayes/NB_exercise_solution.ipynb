{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq_3t_tluNmU"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQVMUZkQHlm2"
      },
      "source": [
        "## 1. Classifying Digits\n",
        "In this part we will test digits classification on the MNIST dataset, using Bernoulli Naive Bayes (a generative model).\n",
        "\n",
        "The MNIST dataset contains 28x28 grayscale images of handwritten digits between 0 and 9 (10 classes). For mathmatical analysis clarity, and for matching expected API, flatten each image to create a 1D array with 784 elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjwjk6pzLE-y"
      },
      "source": [
        "### Loading the MNIST dataset\n",
        "Load the MNIST data set. The digits dataset is one of datasets scikit-learn comes with that do not require the downloading of any file from some external website. Use \n",
        ">```\n",
        "mnist = sklearn.datasets.fetch_mldata('MNIST original')\n",
        "```\n",
        "\n",
        "to fetch the original data. You may set the `data_home` to where you wish to download your data for caching. Each image is already transformed into a 1D integer array $x\\in [0,255]^{784}$, and the corresponding label is an integer $y\\in [0,9]$.\n",
        "\n",
        "Plot a single sample of each digit as the original image, so you get a feeling how the data looks like.\n",
        "\n",
        "Finally, divide your data into train and test sets, using 1/7 of the data for testing.\n",
        "\n",
        "---\n",
        "**Note 1:** Using `digits = sklearn.datasets.load_digits()` will only fetch a very small sample of the original set, with images resized to 8x8. This preprocessing of the data reduces dimensionality and gives invariance to small distortions - however, we will use the original data in this exercise. Feel free to test the proformance of the algorithms below on the preprocessed data as well.\n",
        "\n",
        "**Note 2:**\n",
        "Since ML-Data is deprecated, you may wish to use something like this:\n",
        ">```\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test = x_test.reshape(x_test.shape[0], 784)\n",
        "  ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "05Om0QLxBvvT"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "(x_train_orig, y_train_orig) , (x_test_orig, y_test_orig) = mnist.load_data()\n",
        "x_train_reshaped = x_train_orig.reshape(x_train_orig.shape[0], 784)\n",
        "x_test_reshaped = x_test_orig.reshape(x_test_orig.shape[0], 784)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting a sample per digit from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "for digit in range(10):\n",
        "    # Get relevant subplot\n",
        "    _ = plt.subplot(2, 5, digit+1)\n",
        "    \n",
        "    first_digit_idx = np.argmax(y_train_orig==digit)\n",
        "    plt.imshow(x_train_orig[first_digit_idx], cmap=plt.get_cmap('gray_r'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Divide the dataset using 1/7 split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train_reshaped.shape, x_test_reshaped.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data is already split with test being 1/7 of the data, I did not re-split it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train_reshaped\n",
        "x_test = x_test_reshaped\n",
        "y_train = y_train_orig\n",
        "y_test = y_test_orig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTGjjSKaFfE6"
      },
      "source": [
        "### Bernoulli Naive Bayes\n",
        "If we know how the digits are generated, then we know how to classify them (simply choose the digit class which will maximize the posterior probability) --- but which model should we use for describing the digits generation?\n",
        "\n",
        "In this part we will try a very simplified model of digits creation (which is obviously not the same as the \"real\" model), using a Naive Bayes over an underlying Bernoulli distribution --- that is, we will assume that given a digit class, the pixels of the images are the result of independent coin flips, each with its own \"head\" probability.\n",
        "\n",
        "Note that since we assume each pixl is either 0 (black) or 1 (white), we will need to adjust (preprocess) our data accrodingly (see below).\n",
        "\n",
        "So, the model is stated as follows:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{Domain} && x \\in \\{0,1\\}^{784} \\\\\n",
        "\\text{Prior} && \\pi_j = \\Pr(y=j) \\\\\n",
        "\\text{Likelihood} && P_j(x) = \\Pr(x | y=j) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Where for each $i\\in 0\\ldots 784$ it holds that\n",
        "$$\n",
        "P_{ji}(x_i) = \\Pr(x_i | y=j) =\n",
        "\\begin{cases}\n",
        "p_{ji} & \\text{if } x_i=1 \\\\\n",
        "1-p_{ji} & \\text{if } x_i=0 \\\\\n",
        "\\end{cases}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNjhD3IpL5bC"
      },
      "source": [
        "#### Question 1\n",
        "Write the classification rule based on this Naive Bayes model. \n",
        "How would you esitmate each of the parameters of the model based on the trainning data? \n",
        "\n",
        "\n",
        "**Bonus:** Think of edge cases which may effect your estimator in an undesired way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pN1prGcMqwZ"
      },
      "source": [
        "#### Answer 1\n",
        "\n",
        "**Prior**\n",
        "\n",
        "In our case, this is dicussing the probability of being a digit (overall), per digit j.\n",
        "In order to estimate it, I would sum the total labels of j and divide it by the total number of samples:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{Prior} && \\pi_j = \\Pr(y=j) = \\dfrac{N_{class=j}}{N_{samples}} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "**Likelihood**\n",
        "\n",
        "The probability for specific data point (with set of features) given specific class.\n",
        "\n",
        "For example, in our case let's say we have a data point of picture with number 5, we can check what is the probability of been this data point if it's given that the class is 6.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Resulting posterior prob**\n",
        "\n",
        "The decision rule should be the class which maximzes the postrior $$P(y|x_{i}) = \\frac{P_{j}(x_{i})\\pi_j}{P(x_{i})} $$\n",
        "\n",
        "And Since the denominator is constant that does not depend on $y_{i} $, we can just maximze the numerator\n",
        "\n",
        "$$\\hat{y_{i}} = argmax_{j}\\;P_{j}(x_{i})\\pi_j $$\n",
        "\n",
        "\n",
        "Edge cases which may effect the classifier are images for digits which resemble other digits and thus similar liklihood (and higher compared to other 8 labels) nuder both labels. e.g 4/9, or 3/8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOnkgDIXTMCQ"
      },
      "source": [
        "#### Question 2\n",
        "Run a Naive Bayes classifier on the training data and apply predictions on the test data. Use the [sklearn.naive_bayes.BernoulliNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) implementation (see the [source code for sklearn.naive_bayes](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py) for details).\n",
        "\n",
        "Remember we need to preprocess the data in this case such that each pixel would become either black (0) or white (1). For this, use the `binarize` parameter of the implementation. Set this value to $0$ (this is the default), which in this case would mean every pixel with non-zero value will be set to 1.\n",
        "\n",
        "1. Plot the mean image of each class (estimated $\\hat{p}_{ji}$) and generate one sample of each class (remember, you can do this since this is a generative model). You will need to access the `feature_log_prob_` attribute of the trained model.\n",
        "\n",
        "2. Plot the confusion matrix of your classifier, as claculated on the test data (it is recommended to use [sklearn.metrics.confusion_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)). Calculate the total accuracy (fraction of correctly classified images), and summarize the results in your own words.\n",
        "\n",
        "3. Think of a way you can find the optimal threshold of the binarization part. **There is no need to actually perform this task --- just describe what you would have done.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKdsdegDWaO_"
      },
      "source": [
        "#### Answer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XalqjRWXWS-Y"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "bnb = BernoulliNB(binarize=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = bnb.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds_train = bnb.predict(x_train)\n",
        "preds_test = bnb.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Plot the mean image of each class and generate one sample per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 784)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bnb.feature_log_prob_.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### 1.1. Mean image per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "for digit in range(10):\n",
        "    # Get relevant subplot for the current digit\n",
        "    _ = plt.subplot(2, 5, digit+1) \n",
        "    \n",
        "    # Get the log of the probabillities per pixel for a given class\n",
        "    digit_pixel_log_probas = bnb.feature_log_prob_[digit]\n",
        "    # Evaluate the actual probability out of the log(probability)\n",
        "    digit_pixel_probas = np.exp(digit_pixel_log_probas)\n",
        "    # Get the color based on the raw probability value\n",
        "    mean_digit_pixels = (digit_pixel_probas).reshape((28, 28))\n",
        "    # Plotting the current digit\n",
        "    plt.imshow(mean_digit_pixels, cmap=plt.get_cmap('gray_r'))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### 1.2. Generated sample per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAEWCAYAAACpC6mpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAczElEQVR4nO3dwcsd1f3H8c/3Z+MqG9M8StDYx0UouhMfWku7k0DqRjcFXZQshGwsKLiJ7T/gyl03ASVZiKWgYBaCSBBKoYjPU6TVhhjbag0G84QurNlE4ftbPOPjzfXeueecOTNz5tz3Cy7Pc+/cmTnPfObcnJxzZq65uwAAABDu/8YuAAAAwNTQgAIAAIhEAwoAACASDSgAAIBINKAAAAAi0YACAACI1KkBZWYnzOySmX1sZqdzFQrjIM96kGVdyLMeZFkPS70PlJndJukjScclXZH0nqQn3f0f+YqHoZBnPciyLuRZD7Ksyw86rPsTSR+7+78kycz+IOkxSUtPhMOHD/vm5maHXaKLTz75RNevX7cli6PyJMvx7ezsXHf3jQWLqJsTQ92sC3WzHm11s0sD6m5Jn808vyLpp20rbG5uant7u8Mu0cXW1lbb4qg8yXJ8ZvbpkkXUzYmhbtaFulmPtrrZZQ7UohbZ98YDzeyUmW2b2fbu7m6H3aFnK/Mky8mgbtaFulkP6mZFujSgrkg6OvP8Hkmfz7/J3c+4+5a7b21sLOrRRCFW5kmWk0HdrAt1sx7UzYp0aUC9J+mYmd1nZrdLekLS+TzFwgjIsx5kWRfyrAdZViR5DpS7f2Nmv5H0lqTbJL3s7h9mKxkGRZ71IMu6kGc9yLIuXSaRy93flPRmprJgZORZD7KsC3nWgyzr0akBBQBAicy+m6+der9DoA1f5QIAABCJBhQAAEAkhvBGQNcysFxK/ZhdJ2Y91ItzAH2jBwoAACASDSgAAIBINKAAAAAiMQdK358/kSJmvJ2x+bIxn2Zcs8c7Rxa58mTuYl7MdUMfhjxH6IECAACIRAMKAAAgEkN4Eea7Ame7CmO6DduGDOmSHkZbXm05xyDL7+SqH6FZhG6Dofe8UutK6HptdTPXMiw3hX+7hiwHPVAAAACRaEABAABEogEFAAAQaW3nQKWMj8eM7+cYK+aS3f6kzsFJ3ea6yzUnMMctR0JNYb5HCUI/S3Pva9Wy3LfDwK2GPoap89b6nO9GDxQAAEAkGlAAAACR1nYIL3UYLWV789vg0tv+hA67pA7PDDmENAV9dKu33R5kVurw+rJ9zW+TOrZY6nBYaL3q41YFCNd2TIesE7mGZLkTOQAAQEFoQAEAAESiAQUAABCp6jlQY46P5/7KCYk5GSFS52OEzrtJ3V+t+rhUPPcctFxfG7PuWafIfX6k1s2Yeaj4ztCfhaG5lDI/mB4oAACASDSgAAAAIlU9hJf7svWYYcAcl1jTtZxXjmFbMlku5tiEDu2ELoupm1z63k2uodllxzrmfGhDzmFy1L+2bcYMoZd4q4I29EABAABEWtmAMrOXzeyamX0w89ohM3vbzC43P+/ot5jIhTyrskmW9aBuVoW6uQZCeqDOSjox99ppSRfc/ZikC81zTMNZkWctrossa3JW5FkL6uYaWNmAcvc/Sfrv3MuPSTrX/H5O0uN5i7Wcmd3y6GOby7Y/v8zd9x9t25h9X+zXXeT+W0vLcwrach7ZV6ogy/n60VZ3Qo99W2YpdXEI1M3F+qhvA5wDk6mbqXWs7323/bsZ+m9231LnQN3l7lclqfl557I3mtkpM9s2s+3d3d3E3aFnQXmS5SRQN+tC3awHdbMyvU8id/cz7r7l7lsbGxt97w49Isu6kGc9yLIu5DkNqbcx+MLMjrj7VTM7IulazkK1yX2X4i5SL9WclXr59artRBotzxxCL1dek1tLTDpLKfxy5dS6ElpvC8l60nm2Hetlxze1bs6vF5pf6noJisky9N+SRdNYQraZemug1M/oqd3G4Lykk83vJyW9kac4GAl51oMs60Ke9SDLyoTcxuBVSX+R9GMzu2JmT0l6QdJxM7ss6XjzHBNAnlW5T2RZDepmVaiba2DlEJ67P7lk0SOZy4IBkGdV/u3uWwteJ8sJom5Whbq5BibxVS49zv1Zuc3Qcd0c20/dRmn6OGapchzroc8/hEmdK5XjnMBiYx5r6mK4HHOJh57nVCK+ygUAACASDSgAAIBIkxjC67trtu9LmWNuVRCznVINXc6+b20xleNesgEvFV+4v1CpwxLYU+pxaTv/Si1zn3LUj9RbIeRQSmb0QAEAAESiAQUAABBpEkN4s1K7YmPuWlxK9+A8hhBWS70KqNTjOZVzc5XQO8TPC/37cw3Zpdw5G98Zesh8dn9Tv6KrTzGfI6l3+F9H9EABAABEogEFAAAQiQYUAABApMnNgWpT0rc3576bK9KEHsNS55eVVJZYqfOJcnzje+o3yofewRyLpd6ypY/PwXXPq62u9DFXre/5aKF5Dllv6YECAACIRAMKAAAg0iSG8HIMr6ReRh0q5vL5qV9aX7IcXdUM3eTR93k+5N2UY9+LPaFDczluH8FQ7a1Sh7hDlfrl0H3/Wz+LHigAAIBINKAAAAAi0YACAACINIk5UH3MWcgtdLxZ4vYEQ0oZ669lDkRJUi957qPu5L5NQsx6WGzMY7aOeaV+ldKsvv9dyzXnkNsYAAAAFIQGFAAAQKRJDOHNSh0K6ONSzT5uVdD296xjV3OIHHfc5dj2K7V+pHbjD3336nW4LD5EzN+eenuC0O2Ffi6sUz7fCv2bcwyVDXH7j7HypAcKAAAgEg0oAACASDSgAAAAIk1uDtS8Pm5JP7vN0HkWuS7pXMfx+BKs+5yINjkueY55b0qdjtl36vyr0HlOtc+3SZ3jFXo8277KZYivHaktrzEMfauesXJa2QNlZkfN7B0zu2hmH5rZM83rh8zsbTO73Py8o//iooubN2+KLKtygDzrQN2sDnVzDYQM4X0j6Tl3v1/Sw5KeNrMHJJ2WdMHdj0m60DxHwZr/FZBlXcizAtTNKpFn5VY2oNz9qrv/tfn9f5IuSrpb0mOSzjVvOyfp8Z7KKDPbfwxh2f5mXzczufv+Y35Zm7b1QrcR895vHThwQGNnmartb509nkPve2RfD5Fn6PGdfd/8I0Zo1mPmEvP3hbyvtLqZ+lk0f1zals3q4zOx7Xxs21+mz5NB6uYUxHwupGY/lqhJ5Ga2KelBSe9Kusvdr0p7jSxJd2YvHXpDlnUhz3qQZV3Is17BDSgzOyjpNUnPuvuXEeudMrNtM9ve3d1NKSMyI8u6kGc9yLIu5Fm3oAaUmR3Q3knwiru/3rz8hZkdaZYfkXRt0brufsbdt9x9a2NjI0eZ0QFZ1oU860GWdSHP+oVchWeSXpJ00d1fnFl0XtLJ5veTkt7IX7w9oWOmXeZdLBM6vh9a/lzlStlm875Rs0wV+re2jZu3bSN1WQEmmeesmHM5JNvU+Umr5uz0OR+jtLoZ87eHzidqq5tDz3Xp+9+NRjF5Di335/X8dkqZHxVyH6ifS/q1pL+b2fvNa7+V9IKkP5rZU5L+I+lXvZQQ2dy4cUMiy5ocFHlWgbpZHermGljZgHL3P0ta1sR7JG9x0KeDBw/K3cmyHl+RZx2om9Whbq6Byd+JvM1st1+Obr7UbSzqmlz0O8LEHM9lmbW9j0z6l3qMU9ZrW6ftXGrbTtt6MducotA6tkroeqmf4211urZMSpN6TkRORxkd34UHAAAQiQYUAABAJBpQAAAAkSY/Byp17kHMvIiu5UJ3oXOUQs+B2uepjCH1mI6ZRR9zsWo8l8b8m1LmSiHdkPNBU7dfyuc3PVAAAACRaEABAABEmvwQ3qxc3ep0BZcndKh2apfB1iS1/uXIoo8u/VKGCUrXVjfbht+WrcctRsYVOkUi9ZYxOZRyHtADBQAAEIkGFAAAQCQaUAAAAJGqmgOF9VDK+DfKUfM8iynhthB1S8mp5rmE9EABAABEogEFAAAQiSE8AADQi5qG7ObRAwUAABCJBhQAAEAkGlAAAACRmAOFyeOrHgAAQ6MHCgAAIBINKAAAgEg25JCHme1K+lTSYUnXB9vxcutWjh+5+0aODZFlK/Lsbt3KQZbDmGqeN7R+x3CV0bMctAG1v1OzbXffGnzHlCO7UspeSjmkssoSq5SyU47uSil7KeWQyipLjJLKXUpZSigHQ3gAAACRaEABAABEGqsBdWak/c6jHN2VUvZSyiGVVZZYpZSdcnRXStlLKYdUVllilFTuUsoyejlGmQMFAAAwZQzhAQAARBq0AWVmJ8zskpl9bGanB973y2Z2zcw+mHntkJm9bWaXm593DFCOo2b2jpldNLMPzeyZscrS1Vh5kmV+1M168iTLerKUyLPZZ5F5DtaAMrPbJP1e0i8lPSDpSTN7YKj9Szor6cTca6clXXD3Y5IuNM/79o2k59z9fkkPS3q6OQ5jlCXZyHmeFVlmQ93cN/k8yXLf5LOUyHNGmXm6+yAPST+T9NbM8+clPT/U/pt9bkr6YOb5JUlHmt+PSLo0ZHma/b4h6XgJZZlSnmRZT5bkSZZkSZ5TzHPIIby7JX028/xK89qY7nL3q5LU/LxzyJ2b2aakByW9O3ZZEpSWJ1mmKy1LiTxTkeWcCWcpkef3lJTnkA0oW/Da2l4CaGYHJb0m6Vl3/3Ls8iQgzwZZ1mXieZLljIlnKZHnLUrLc8gG1BVJR2ee3yPp8wH3v8gXZnZEkpqf14bYqZkd0N5J8Iq7vz5mWTooLU+yTFdalhJ5piLLRgVZSuS5r8Q8h2xAvSfpmJndZ2a3S3pC0vkB97/IeUknm99Pam9ctVdmZpJeknTR3V8csywdlZYnWaYrLUuJPFORparJUiJPSQXnOfDEr0clfSTpn5J+N/C+X5V0VdLX2mvVPyXph9qbuX+5+XlogHL8QntdsH+T9H7zeHSMskw1T7KsJ0vyJEuyJM+p5smdyAEAACJxJ3IAAIBINKAAAAAi0YACAACIRAMKAAAgEg0oAACASDSgAAAAItGAAgAAiEQDCgAAIBINKAAAgEg0oAAAACLRgAIAAIhEAwoAACASDSgAAIBINKAAAAAi0YACAACIRAMKAAAgEg0oAACASDSgAAAAItGAAgAAiEQDCgAAIBINKAAAgEg0oAAAACLRgAIAAIhEAwoAACASDSgAAIBINKAAAAAi0YACAACIRAMKAAAgEg0oAACASDSgAAAAItGAAgAAiEQDCgAAIBINKAAAgEidGlBmdsLMLpnZx2Z2OlehMA7yrAdZ1oU860GW9TB3T1vR7DZJH0k6LumKpPckPenu/8hXPAyFPOtBlnUhz3qQZV269ED9RNLH7v4vd78p6Q+SHstTLIyAPOtBlnUhz3qQZUV+0GHduyV9NvP8iqSftq1w+PBh39zc7LDL+uzs7Nzy/KGHHuptX5988omuX79uSxZH5UmW49vZ2bnu7hsLFlE3J4a6WRfqZj3a6maXBtSiDX5vPNDMTkk6JUn33nuvtre3O+yyPma3HsY+j8/W1lZrURa8dkueZFkWM/t02aIFr1E3C0bdrAt1sx5tdbPLEN4VSUdnnt8j6fP5N7n7GXffcvetjY1FDfL15u63PEa0Mk+ynAzqZl2om0uY2f6j7+1n2gd1syJdGlDvSTpmZveZ2e2SnpB0Pk+xMALyrAdZ1oU860GWFUkewnP3b8zsN5LeknSbpJfd/cNsJcOgyLMeZFkX8qwHWdalyxwoufubkt7MVBaMjDzrQZZ1Ic96kGU9OjWggNKEzlOYn282u97Ic9EABOq7rvJZgDZ8lQsAAEAkGlAAAACRJj+E1zZkQ/fr+gnNfP68aVuP4T0AwDx6oAAAACLRgAIAAIhEAwoAACDS5OdAjTknhbkxdWqbH8WcOwCARA8UAABANBpQAAAAkSY/hJdDzCXtKdtsu+v1vLbhotBlNSpluLT24wx0keMzi889TAU9UAAAAJFoQAEAAESiAQUAABCp6jlQqfNmlq0XM/4euqxtPlRouVYtq0HqV63EHN+u2wgt46r31ijX31/7eV6q0OMeU3dC61WObbThPErT9+1epvCZSQ8UAABAJBpQAAAAkaoewpuV2tWb2n0cOvSXqzu8xO7NMeQYbitpvVrkGt5cVq+oK/3KMeySWjf7GKZLHT5c93Mnx3SJHP8Wl5IDPVAAAACRaEABAABEogEFAAAQqeo5UKm3CwjdRsy8jtBlbdsvZdy3NKk5LHsfxz1cjnmAqdsMXafLe0PVcI70kWXucgyxzdC5Nus4PyrHv6kp+1plrDmP9EABAABEogEFAAAQqeohvFl9X3K5jt25fcpxOfS8voch1vEcyPE39nH36j7UnmffWfbxLQFdt9dlvVrOh76HtGO2n2O9IdEDBQAAEGllA8rMXjaza2b2wcxrh8zsbTO73Py8o99iIhfyrMomWdaDulkV6uYaCOmBOivpxNxrpyVdcPdjki40zzENZ0WetbgusqzJWZFnLaiba2BlA8rd/yTpv3MvPybpXPP7OUmP5y3Wrcxs/xH6vvn3ti0L5e63PEKXxehaxlVKyDNEzLFue5RS5p58pQlkuUqOupnLmOfSVOvmfH4pn8F9HOe2baYui1BF3UzVVp/b6ljqesv23ffnSeocqLvc/aokNT/vzFckjIA860GWdSHPepBlZXqfRG5mp8xs28y2d3d3+94dekSWdSHPepBlXchzGlIbUF+Y2RFJan5eW/ZGdz/j7lvuvrWxsZG0s9Au1ZjuwJjt5ByWW1WW0P1l7qYMyjNHlqFShwJCl+U6V9r2PdKw1KB1s03KOR8zNN7HMG5bmUvOc8i6GSPl8yz0fbnq2IBDtcXUzTY5jkUfQ+Ft2bd9toduM0VqA+q8pJPN7yclvZG4HZSBPOtBlnUhz3qQZWVCbmPwqqS/SPqxmV0xs6ckvSDpuJldlnS8eY4JIM+q3CeyrAZ1syrUzTWw8k7k7v7kkkWPZC4LBkCeVfm3u28teJ0sJ4i6WRXq5hqo+qtcZsc/Y8Y4Z9/bNoba9r7QZfNCx4iHuKx6aKHHve/jOb+9HOdALWKOTWr9i8k+pVypaqxzufVRB3J8jrctW/dc+/j7+/hcLLFO81UuAAAAkWhAAQAARKpqCK+PbvzUrt7UIaF1FjpUlkNbJjHDsaHbbHvvlM6HUsuaq1zU2/6kDuXkGPIhy1v1MYy27DMt12d36HaGzJYeKAAAgEg0oAAAACJVNYSX68qtZfq4kg+L9d3tm3olX9tQwKI7ny/bX9u+1+F86bt+pHb3p5aL+r7a0Fel1ngVbC59XNmY8r5cxhqupQcKAAAgEg0oAACASDSgAAAAIlU1BypGH5dZhm6fORKr1XBH4xx3SK9FH3PAcpwTodlKaXdIX3d935qE455f6OfkOnzzwir0QAEAAESiAQUAABBpbYfwZqV2A/fRZcnl0HuGPrY5luUaDlo3qcN7Qw7DY7kxp0OEov7ll3rrl1QpXwzfN3qgAAAAItGAAgAAiEQDCgAAINLk50CV8tULqZd7zi9b57H51K8+aZMyFh/zdS19z/9Yd6GXSvdxuTzzZvJKvew99VYhofsm1+WGziz1FiZjZUgPFAAAQCQaUAAAAJEmP4SXOoSSo8svdRt0GS/W9zBMH3fYTR1CKM3Ozs7+31JyWXMMmZb8901RjqHx0PVKGbpZVynHO9e3PnQtRx/ogQIAAIhEAwoAACASDSgAAIBIk58DlesS5VnL5lmMeZsEdJfjK1nm1XIbg4ceekjb29tjFyNZjkujsVzq8c09f3B+naG/TqRGuerHOv6bt7IHysyOmtk7ZnbRzD40s2ea1w+Z2dtmdrn5eUf/xUUXN2/eFFlW5QB51oG6WR3q5hoIGcL7RtJz7n6/pIclPW1mD0g6LemCux+TdKF5joI1/0Mgy7qQZwWom1Uiz8qtbEC5+1V3/2vz+/8kXZR0t6THJJ1r3nZO0uM9lTGZu+8/Qt/n7jKz/Uebtvct296YXckHDhzQVLPMLVcmoedAT74mz26om2HmPyNTzu22bbRtbzaftvfGLKNujqft2KeeI2OJmkRuZpuSHpT0rqS73P2qtNfIknRn9tKhN2RZF/KsB1nWhTzrFdyAMrODkl6T9Ky7fxmx3ikz2zaz7d3d3ZQyIjOyrAt51oMs60KedQtqQJnZAe2dBK+4++vNy1+Y2ZFm+RFJ1xat6+5n3H3L3bc2NjZylBkdkGVdyLMeZFkX8qxfyFV4JuklSRfd/cWZReclnWx+PynpjfzFWy107LzN/DyIZeOube+bX9bHvIqu22yOUbFZhupjPkaOsrTpca7N5PPMoe2caDv2pcytmFLdjPmsy/H53Lbvwk0izz60/XsaOqdtbN+WcWdnZ+l7Qu4D9XNJv5b0dzN7v3ntt5JekPRHM3tK0n8k/apbcdG3GzduSGRZk4MizypQN6tD3VwDKxtQ7v5nScua+o/kLQ76dPDgQbk7WdbjK/KsA3WzOtTNNVDVncjbugBju4m7vm+2LG3vWzSkELLNdZOa7bL1Yo57qFqy6+PYpEqti7NlntKxn4L54zl77FPq4qr1QstS0nm7DnL8+1eyb/+Gra2tpe/hu/AAAAAi0YACAACIRAMKAAAg0uTnQOUYV28b009536r1QpchDMcwr5KOZ4763TY3hnkzYULnmoZuI0ZbXjnKheX6mFtYU070QAEAAESiAQUAABBp8kN4s1K741PXCx1eqKnLshZkMqyY4Zsc9S/0fbmGo2o/n3J/JsZsM3V/6K6PjFJvdVEieqAAAAAi0YACAACIRAMKAAAgUlVzoGLGT/ueozS1sVygT33XzaHnJFG/v5N7zlrf20A/t6UI/fqWmm5LQQ8UAABAJBpQAAAAkaoawosxhe5BoBa57ga+rIu/7VJp6jpwqxzDdjluDzL1ukkPFAAAQCQaUAAAAJFoQAEAAERa2zlQAIaT6+tU+JolYDxTqC9D3tKEHigAAIBINKAAAAAi2ZBdcma2K+lTSYclXR9sx8utWzl+5O4bOTZElq3Is7t1KwdZDmOqed7Q+h3DVUbPctAG1P5OzbbdfWvwHVOO7EopeynlkMoqS6xSyk45uiul7KWUQyqrLDFKKncpZSmhHAzhAQAARKIBBQAAEGmsBtSZkfY7j3J0V0rZSymHVFZZYpVSdsrRXSllL6UcUllliVFSuUspy+jlGGUOFAAAwJQxhAcAABBp0AaUmZ0ws0tm9rGZnR543y+b2TUz+2DmtUNm9raZXW5+3jFAOY6a2TtmdtHMPjSzZ8YqS1dj5UmW+VE368mTLOvJUiLPZp9F5jlYA8rMbpP0e0m/lPSApCfN7IGh9i/prKQTc6+dlnTB3Y9JutA879s3kp5z9/slPSzp6eY4jFGWZCPneVZkmQ11c9/k8yTLfZPPUiLPGWXm6e6DPCT9TNJbM8+fl/T8UPtv9rkp6YOZ55ckHWl+PyLp0pDlafb7hqTjJZRlSnmSZT1ZkidZkiV5TjHPIYfw7pb02czzK81rY7rL3a9KUvPzziF3bmabkh6U9O7YZUlQWp5kma60LCXyTEWWcyacpUSe31NSnkM2oGzBa2t7CaCZHZT0mqRn3f3LscuTgDwbZFmXiedJljMmnqVEnrcoLc8hG1BXJB2deX6PpM8H3P8iX5jZEUlqfl4bYqdmdkB7J8Er7v76mGXpoLQ8yTJdaVlK5JmKLBsVZCmR574S8xyyAfWepGNmdp+Z3S7pCUnnB9z/IuclnWx+P6m9cdVemZlJeknSRXd/ccyydFRanmSZrrQsJfJMRZaqJkuJPCUVnOfAE78elfSRpH9K+t3A+35V0lVJX2uvVf+UpB9qb+b+5ebnoQHK8QvtdcH+TdL7zePRMcoy1TzJsp4syZMsyZI8p5ondyIHAACIxJ3IAQAAItGAAgAAiEQDCgAAIBINKAAAgEg0oAAAACLRgAIAAIhEAwoAACASDSgAAIBI/w9fxThz7UlntwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Function to generate images from predicted probabilities\n",
        "def generate_sample(feature_log_prob):\n",
        "    shape_n = feature_log_prob.shape[0]\n",
        "    # Sample uniform random number between 0-1 per pixel for the generated sample\n",
        "    random_nums = np.round(np.random.rand(784), 2)\n",
        "    pixels = np.zeros(shape_n)\n",
        "    \n",
        "    # Per random pixel value if the random value is smaller than the proba -> set pixel to black\n",
        "    for i in range(shape_n):\n",
        "        if random_nums[i] <= np.exp(feature_log_prob[i]):\n",
        "            pixels[i] = 1\n",
        "    return pixels\n",
        "\n",
        "\n",
        "# Generating and plotting the generated samples\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "for digit in range(10):\n",
        "    # Get relevant subplot for the current digit\n",
        "    _ = plt.subplot(2, 5, digit+1) \n",
        "    \n",
        "    # Get the log of the probabillities per pixel for a given class\n",
        "    digit_pixel_log_probas = bnb.feature_log_prob_[digit]\n",
        "    # Generate sample based on the log probabilities\n",
        "    generated_pixels = generate_sample(digit_pixel_log_probas).reshape((28,28))\n",
        "    # Plotting the current generated digit\n",
        "    plt.imshow(generated_pixels, cmap=plt.get_cmap('gray_r'))\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. Plotting the confusion matrix of the classifier & small analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted_0</th>\n",
              "      <th>predicted_1</th>\n",
              "      <th>predicted_2</th>\n",
              "      <th>predicted_3</th>\n",
              "      <th>predicted_4</th>\n",
              "      <th>predicted_5</th>\n",
              "      <th>predicted_6</th>\n",
              "      <th>predicted_7</th>\n",
              "      <th>predicted_8</th>\n",
              "      <th>predicted_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1085</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>852</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>34</td>\n",
              "      <td>844</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>49</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>795</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>129</td>\n",
              "      <td>30</td>\n",
              "      <td>627</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "      <td>851</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>871</td>\n",
              "      <td>27</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>76</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>758</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>74</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   predicted_0  predicted_1  predicted_2  predicted_3  predicted_4  \\\n",
              "0          887            0            4            7            2   \n",
              "1            0         1085           10            5            0   \n",
              "2           19            8          852           29           17   \n",
              "3            5           15           34          844            0   \n",
              "4            2            6            4            0          795   \n",
              "5           23           12            7          129           30   \n",
              "6           18           18           15            2           13   \n",
              "7            1           24           14            4           15   \n",
              "8           16           23           13           76           17   \n",
              "9            9           13            5            9           74   \n",
              "\n",
              "   predicted_5  predicted_6  predicted_7  predicted_8  predicted_9  \n",
              "0           41           16            1           22            0  \n",
              "1            9            6            0           19            1  \n",
              "2            4           32           14           55            2  \n",
              "3           13            9           15           49           26  \n",
              "4            4           21            1           23          126  \n",
              "5          627           16            8           21           19  \n",
              "6           35          851            0            6            0  \n",
              "7            0            0          871           27           72  \n",
              "8           22            7            6          758           36  \n",
              "9            8            0           24           24          843  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_test,\n",
        "                               y_pred=preds_test)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, columns=[f'predicted_{i}' for i in range(0,10)])\n",
        "conf_matrix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 84.13%\n"
          ]
        }
      ],
      "source": [
        "true_preds_count = np.trace(conf_matrix)\n",
        "accuracy = true_preds_count / x_test.shape[0]\n",
        "print(f\"Model Accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "High errors for digit 2:\n",
            "predicted_8    55\n",
            "Name: 2, dtype: int64\n",
            "\n",
            "High errors for digit 4:\n",
            "predicted_9    126\n",
            "Name: 4, dtype: int64\n",
            "\n",
            "High errors for digit 5:\n",
            "predicted_3    129\n",
            "Name: 5, dtype: int64\n",
            "\n",
            "High errors for digit 7:\n",
            "predicted_9    72\n",
            "Name: 7, dtype: int64\n",
            "\n",
            "High errors for digit 8:\n",
            "predicted_3    76\n",
            "Name: 8, dtype: int64\n",
            "\n",
            "High errors for digit 9:\n",
            "predicted_4    74\n",
            "Name: 9, dtype: int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "high_error_threshold = 50\n",
        "\n",
        "for digit in range(10):\n",
        "    \n",
        "    \n",
        "    # Get the row of current digit\n",
        "    digit_hits = conf_matrix_df.iloc[digit]\n",
        "    \n",
        "    # Filter predictions with high error rate based on thershold\n",
        "    high_preds_count = digit_hits[digit_hits > high_error_threshold]\n",
        "    # Drop the correctly predicted samples (as they have high hit rates of course)\n",
        "    high_preds_count.drop(labels=f'predicted_{digit}', inplace=True)\n",
        "    \n",
        "    # Print the mistakes that passed the threshold\n",
        "    if len(high_preds_count) > 0:\n",
        "        print(f\"High errors for digit {digit}:\\n{str(high_preds_count)}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Summarized results in my words:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we see above the model accuracy is 84.13% (not very bad for our naive assumption), in addition looking on high error rates we had (setting the threshold of at least 50 samples classified wrongly as we see in the boolean indexing above) we can see that we had we had some higher error rates in the next cases:\n",
        "\n",
        "1. Classifiying 2 as 8 (55 times) - This can be expected given the similar shapes of the digits.\n",
        "2. Classifiying 4 as 9 (126 times!) - This can be expected given the similar shapes of the digits.\n",
        "3. Classifiying 5 as 3 (129 times!) - This can be expected given the similar shapes of the digits in their lower part.\n",
        "4. Classifiying 7 as 9 (72 times) - This can be expected given the similar shapes of the digits in the right part.\n",
        "5. Classifiying 8 as 3 (76 times) - This can be expected given the similar shapes of the digits in the right part.\n",
        "6. Classifiying 9 as 4 (74 times) - This can be expected given the similar shapes.\n",
        "\n",
        "Looking on the above errors, I'd say that the biggest \"problems\" in the model are:\n",
        "- The miss-classification of 3-8 (125 mistakes)\n",
        "- The miss-classification of 4-9 (200 mistakes) \n",
        "- The miss-classification of 3-5 (142 times)\n",
        "\n",
        "If I had to do another iteration and improve the model, I would have looked on the specific samples with the higher error rates per problem, trying to understand if there is any similarity between them and a specific phenomena that is not represented in the train set / any phenomena that is causing a bias in the train set like missing samples of a specific digit drawing type.\n",
        "\n",
        "Additionally, I would have tried to give a name to such phenomena and try to handle it by providing additional labels / samples / features could have helped the model defrentiating the samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3. Optimal threshold of the binarization part - ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I think that what I would have done in order to optimize the binarization threshold is:\n",
        "1. Split the dataset to: train / validation / test sets (train - 70%, validation - 10%, test - 20%)\n",
        "2. Try to optimize the threshold of the binarization by using the train and validation set and evaluating the best X models I trained on the test set to evaluate the \"real\" production expected performance:\n",
        "- Training models with different thresholds starting from 1 to 256\n",
        "- Evaluating the performance on the train and validation sets for the different thresholds, plotting a graph that presents the error rate (based on accuracy / f1 / precision / recall - depends on the problem and what's more important to us to solve) and look for the top X thresholds where we have optimal performance on the train + validation.\n",
        "- Evaluating the performance of the top X models on the test set and trying to evaluate which model had the best performance and makes more sense.\n",
        "\n",
        "\n",
        "**Additional idea** - Use a similar idea to the above split but instead use stratified cross validation here with 10 folds, this will also help us understanding the stabillity of the different thresholds per model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKSgnectrTJ1"
      },
      "source": [
        "## 2. Classifing Text Documents using Multinomial Naive Bayes\n",
        "In this exercise you will classify the \"20 newsgroups\" data set using your own naive bayes classifier and compare to the scikit learn built in version.\n",
        "\n",
        "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon messages posted before and after a specific date.\n",
        "\n",
        "\n",
        "* Load the **train** data using `from sklearn.datasets import fetch_20newsgroups`. remove headers, footers and quotes (see documentation)\n",
        "* Use `sklearn.feature_extraction.text import CountVectorizer` to count words (stop_words='english')\n",
        "* Write a class `NaiveBayes(BaseEstimator, ClassifierMixin)` and implement its `fit`, `predict` and `predict_proba` methods.\n",
        "* use `sklearn.pipeline.make_pipeline` to chain the vectroizer and model.\n",
        "* note: limit the vocuabolary size if you suffer memory issues\n",
        "* compare the accuracy over the **test** data. You can use `accuracy_score, classification_report`\n",
        "* compare to the built in `sklearn.naive_bayes.MultinomialNB`. If there are differences try to think why\n",
        "* plot the learning curve - is the model in the bias or variance regime (you can use the built in model for doing the analysis)\n",
        "* optimize performance in respect to vectorizer hyper parameters (e.g. max_features, max_df etc.).\n",
        "\n",
        "### Optional: Model interpretability\n",
        "Find the most important features for a **specific** decision of a NB classifier.\n",
        "Because the model has learned the prior $p(x_i|c)$ during the training, the contribution of an individual feature value can be easily measured by the posterior, $p(c|x_i)=p(c)p(x_i|c)/p(x_i)$\n",
        "Implement a function which gets a scikit-learn NB model as input and returns $P(c|x_i)$:\n",
        "\n",
        "`def calc_p_c_given_xi(model)`\n",
        "\n",
        "Hint: Use the following model properties:\n",
        "\n",
        "* `model.class_log_prior_`\n",
        "* `model.feature_log_prob_`\n",
        "\n",
        "Note: remember these are logs and you need to use np.exp and normalize to get $P(c|x_i)$ \n",
        "Another hint: use numpy built-in broadcasting property.\n",
        "\n",
        "* Use the interpretation to examine errors of the classifier where $\\hat{c}\\ne c$. Which top words support the correct class and which support the wrong class? You can use the `print_txt` below to color words. \n",
        "\n",
        "Bonus: How can you correct the analyzed error? \n",
        "\n",
        "To read more about model interpretation, see the blogpost below and my tutorial:\n",
        "* https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html\n",
        "* https://github.com/chanansh/right_but_why"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "ds_dict_train = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_dict_train.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train = ds_dict_train.get('data')\n",
        "labels_train = ds_dict_train.get('target')\n",
        "classes_train = ds_dict_train.get('target_names')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating words vectorizer and apply on the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101322\n"
          ]
        }
      ],
      "source": [
        "cvectorizer = CountVectorizer(stop_words='english').fit(data_train)\n",
        "print(len(cvectorizer.vocabulary_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparse matrix shape: (11314, 101322)\n",
            "Number of non-zeros: 755809\n",
            "Sparsity: 0.07%\n"
          ]
        }
      ],
      "source": [
        "data_train_vectorized = cvectorizer.transform(data_train)\n",
        "\n",
        "print('Sparse matrix shape:', data_train_vectorized.shape)\n",
        "print('Number of non-zeros:', data_train_vectorized.nnz)\n",
        "print('Sparsity: %.2f%%' % (100.0 * data_train_vectorized.nnz / (data_train_vectorized.shape[0] * data_train_vectorized.shape[1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample -\n",
            "I have win 3.0 and downloaded several icons and BMP's but I can't figure out\n",
            "how to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\n",
            "\n",
            "\n",
            "Thanx,\n",
            "\n",
            "-Brando\n",
            "\n",
            "\n",
            "Vectorized sample -\n",
            "  (0, 19162)\t1\n",
            "  (0, 23319)\t1\n",
            "  (0, 23947)\t1\n",
            "  (0, 26651)\t1\n",
            "  (0, 34856)\t1\n",
            "  (0, 40177)\t1\n",
            "  (0, 46158)\t1\n",
            "  (0, 48451)\t2\n",
            "  (0, 88284)\t1\n",
            "  (0, 92600)\t1\n",
            "  (0, 95442)\t1\n",
            "  (0, 96428)\t1\n"
          ]
        }
      ],
      "source": [
        "# Print a sample from the data\n",
        "sample_idx=8\n",
        "print(f\"Sample -\\n{data_train[sample_idx]}\\n\\n\")\n",
        "print(f\"Vectorized sample -\\n{data_train_vectorized[sample_idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class NaiveBayes(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "        # calculate priors and likelihoods\n",
        "        classes, counts = np.unique(self.y, return_counts=True)\n",
        "        prior = np.zeros(len(classes),)\n",
        "        features_probs = np.zeros((len(classes), self.X.shape[1]))\n",
        "        samples_count = len(self.y)\n",
        "\n",
        "        for c in classes:\n",
        "            # Evaluate the prior per class\n",
        "            prior[c] = counts[c] / samples_count\n",
        "            # Evaluate the smoothed feature conditional proba\n",
        "            features_probs[c] = (self.X[self.y==c].sum(axis=0) + self.alpha)/(self.X[self.y==c].sum() + self.alpha * self.X.shape[1])\n",
        "\n",
        "        self.prior = prior\n",
        "        self.likelihood = features_probs\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_log_proba(self, x):\n",
        "        \n",
        "        self.X_test = x\n",
        "        \n",
        "        # posterior\n",
        "        self.log_probs = (self.X_test @ np.log(self.likelihood.T)) + np.log(self.prior.T)\n",
        "        \n",
        "        return self.log_probs\n",
        "\n",
        "    def predict(self, X):\n",
        "        \n",
        "        self.X = X\n",
        "        \n",
        "        # argmax for prediction\n",
        "        self.y_pred = np.argmax(self.predict_log_proba(self.X), axis=1)\n",
        "        \n",
        "        return self.y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Loading test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_dict_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "data_test = ds_dict_train.get('data')\n",
        "labels_test = ds_dict_train.get('target')\n",
        "classes_test = ds_dict_train.get('target_names')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparse matrix shape: (11314, 101322)\n",
            "Number of non-zeros: 755809\n",
            "Sparsity: 0.07%\n"
          ]
        }
      ],
      "source": [
        "data_test_vectorized = cvectorizer.transform(data_test)\n",
        "\n",
        "print('Sparse matrix shape:', data_test_vectorized.shape)\n",
        "print('Number of non-zeros:', data_test_vectorized.nnz)\n",
        "print('Sparsity: %.2f%%' % (100.0 * data_test_vectorized.nnz / (data_test_vectorized.shape[0] * data_test_vectorized.shape[1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Use make_pipeline for the CountVectorizer + NaiveBayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([('countVectorizer', CountVectorizer(stop_words='english')), ('nb', NaiveBayes())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('countVectorizer', CountVectorizer(stop_words='english')),\n",
              "                ('nb', NaiveBayes())])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the fit method\n",
        "pipe.fit(data_train, labels_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 4, 4, ..., 3, 1, 8])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the predict method\n",
        "pipe.predict(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Evaluate my implementation test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "test_preds_mine = pipe.predict(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.75      0.84       480\n",
            "           1       0.73      0.84      0.78       584\n",
            "           2       1.00      0.05      0.10       591\n",
            "           3       0.68      0.88      0.77       590\n",
            "           4       0.94      0.85      0.89       578\n",
            "           5       0.67      0.94      0.78       593\n",
            "           6       0.92      0.84      0.88       585\n",
            "           7       0.94      0.83      0.88       594\n",
            "           8       0.96      0.82      0.89       598\n",
            "           9       0.98      0.86      0.91       597\n",
            "          10       0.63      0.93      0.75       600\n",
            "          11       0.75      0.91      0.82       595\n",
            "          12       0.92      0.80      0.86       591\n",
            "          13       0.93      0.92      0.93       594\n",
            "          14       0.93      0.89      0.91       593\n",
            "          15       0.68      0.96      0.80       599\n",
            "          16       0.87      0.90      0.88       546\n",
            "          17       0.81      0.90      0.85       564\n",
            "          18       0.79      0.90      0.84       465\n",
            "          19       0.97      0.49      0.65       377\n",
            "\n",
            "    accuracy                           0.82     11314\n",
            "   macro avg       0.85      0.81      0.80     11314\n",
            "weighted avg       0.85      0.82      0.80     11314\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "print(classification_report(y_pred=test_preds_mine, y_true=labels_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Compare sklearn test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb = MultinomialNB().fit(data_train_vectorized, labels_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_preds_mnb = mnb.predict(data_test_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.75      0.84       480\n",
            "           1       0.73      0.84      0.78       584\n",
            "           2       1.00      0.05      0.10       591\n",
            "           3       0.68      0.88      0.77       590\n",
            "           4       0.94      0.85      0.89       578\n",
            "           5       0.67      0.94      0.78       593\n",
            "           6       0.92      0.84      0.88       585\n",
            "           7       0.94      0.83      0.88       594\n",
            "           8       0.96      0.82      0.89       598\n",
            "           9       0.98      0.86      0.91       597\n",
            "          10       0.63      0.93      0.75       600\n",
            "          11       0.75      0.91      0.82       595\n",
            "          12       0.92      0.80      0.86       591\n",
            "          13       0.93      0.92      0.93       594\n",
            "          14       0.93      0.89      0.91       593\n",
            "          15       0.68      0.96      0.80       599\n",
            "          16       0.87      0.90      0.88       546\n",
            "          17       0.81      0.90      0.85       564\n",
            "          18       0.79      0.90      0.84       465\n",
            "          19       0.97      0.49      0.65       377\n",
            "\n",
            "    accuracy                           0.82     11314\n",
            "   macro avg       0.85      0.81      0.80     11314\n",
            "weighted avg       0.85      0.82      0.80     11314\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_pred=test_preds_mnb, y_true=labels_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultinomialNB (sklearn) accuracy: 81.77%\n",
            "MultinomialNB (my implementation) accuracy: 81.77%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_pred=test_preds_mnb, y_true=labels_test)\n",
        "my_accuracy = accuracy_score(y_pred=test_preds_mine, y_true=labels_test)\n",
        "print(f\"MultinomialNB (sklearn) accuracy: {round(accuracy*100,2)}%\")\n",
        "print(f\"MultinomialNB (my implementation) accuracy: {round(my_accuracy*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We got the same performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Plot the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "estimator = MultinomialNB()\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(estimator=estimator,\n",
        "                                                        X=data_train_vectorized,\n",
        "                                                        y=labels_train,\n",
        "                                                        train_sizes=[i*0.1 for i in range(1,11)])\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot learning curve\n",
        "axes = plt.gca()\n",
        "axes.grid()\n",
        "axes.fill_between(\n",
        "    train_sizes,\n",
        "    train_scores_mean - train_scores_std,\n",
        "    train_scores_mean + train_scores_std,\n",
        "    alpha=0.1,\n",
        "    color=\"r\",\n",
        ")\n",
        "axes.fill_between(\n",
        "    train_sizes,\n",
        "    test_scores_mean - test_scores_std,\n",
        "    test_scores_mean + test_scores_std,\n",
        "    alpha=0.1,\n",
        "    color=\"g\",\n",
        ")\n",
        "axes.plot(\n",
        "    train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
        ")\n",
        "axes.plot(\n",
        "    train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Validation score\"\n",
        ")\n",
        "axes.legend(loc=\"best\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optimize performance in respect to vectorizer hyper parameters (e.g. max_features, max_df etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting on params - 500 0.3 0.3\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.3 0.3\n",
            "Fitting on params - 500 0.3 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.3 0.4\n",
            "Fitting on params - 500 0.3 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.3 0.5\n",
            "Fitting on params - 500 0.3 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.3 1.0\n",
            "Fitting on params - 500 0.3 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 2\n",
            "Fitting on params - 500 0.3 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 3\n",
            "Fitting on params - 500 0.3 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 4\n",
            "Fitting on params - 500 0.3 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 5\n",
            "Fitting on params - 500 0.3 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 10\n",
            "Fitting on params - 500 0.3 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 20\n",
            "Fitting on params - 500 0.3 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.3 50\n",
            "Fitting on params - 500 0.4 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.4 0.4\n",
            "Fitting on params - 500 0.4 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.4 0.5\n",
            "Fitting on params - 500 0.4 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.4 1.0\n",
            "Fitting on params - 500 0.4 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 2\n",
            "Fitting on params - 500 0.4 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 3\n",
            "Fitting on params - 500 0.4 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 4\n",
            "Fitting on params - 500 0.4 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 5\n",
            "Fitting on params - 500 0.4 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 10\n",
            "Fitting on params - 500 0.4 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 20\n",
            "Fitting on params - 500 0.4 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.4 50\n",
            "Fitting on params - 500 0.5 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.5 0.5\n",
            "Fitting on params - 500 0.5 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  500 0.5 1.0\n",
            "Fitting on params - 500 0.5 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 2\n",
            "Fitting on params - 500 0.5 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 3\n",
            "Fitting on params - 500 0.5 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 4\n",
            "Fitting on params - 500 0.5 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 5\n",
            "Fitting on params - 500 0.5 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 10\n",
            "Fitting on params - 500 0.5 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 20\n",
            "Fitting on params - 500 0.5 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  500 0.5 50\n",
            "Fitting on params - 500 1 1.0\n",
            "Fitting on params - 500 1 2\n",
            "Fitting on params - 500 1 3\n",
            "Fitting on params - 500 1 4\n",
            "Fitting on params - 500 1 5\n",
            "Fitting on params - 500 1 10\n",
            "Fitting on params - 500 1 20\n",
            "Fitting on params - 500 1 50\n",
            "Fitting on params - 500 2 2\n",
            "Fitting on params - 500 2 3\n",
            "Fitting on params - 500 2 4\n",
            "Fitting on params - 500 2 5\n",
            "Fitting on params - 500 2 10\n",
            "Fitting on params - 500 2 20\n",
            "Fitting on params - 500 2 50\n",
            "Fitting on params - 500 3 3\n",
            "Fitting on params - 500 3 4\n",
            "Fitting on params - 500 3 5\n",
            "Fitting on params - 500 3 10\n",
            "Fitting on params - 500 3 20\n",
            "Fitting on params - 500 3 50\n",
            "Fitting on params - 500 5 5\n",
            "Fitting on params - 500 5 10\n",
            "Fitting on params - 500 5 20\n",
            "Fitting on params - 500 5 50\n",
            "Fitting on params - 500 10 10\n",
            "Fitting on params - 500 10 20\n",
            "Fitting on params - 500 10 50\n",
            "Fitting on params - 2000 0.3 0.3\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.3 0.3\n",
            "Fitting on params - 2000 0.3 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.3 0.4\n",
            "Fitting on params - 2000 0.3 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.3 0.5\n",
            "Fitting on params - 2000 0.3 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.3 1.0\n",
            "Fitting on params - 2000 0.3 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 2\n",
            "Fitting on params - 2000 0.3 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 3\n",
            "Fitting on params - 2000 0.3 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 4\n",
            "Fitting on params - 2000 0.3 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 5\n",
            "Fitting on params - 2000 0.3 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 10\n",
            "Fitting on params - 2000 0.3 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 20\n",
            "Fitting on params - 2000 0.3 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.3 50\n",
            "Fitting on params - 2000 0.4 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.4 0.4\n",
            "Fitting on params - 2000 0.4 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.4 0.5\n",
            "Fitting on params - 2000 0.4 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.4 1.0\n",
            "Fitting on params - 2000 0.4 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 2\n",
            "Fitting on params - 2000 0.4 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 3\n",
            "Fitting on params - 2000 0.4 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 4\n",
            "Fitting on params - 2000 0.4 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 5\n",
            "Fitting on params - 2000 0.4 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 10\n",
            "Fitting on params - 2000 0.4 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 20\n",
            "Fitting on params - 2000 0.4 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.4 50\n",
            "Fitting on params - 2000 0.5 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.5 0.5\n",
            "Fitting on params - 2000 0.5 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  2000 0.5 1.0\n",
            "Fitting on params - 2000 0.5 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 2\n",
            "Fitting on params - 2000 0.5 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 3\n",
            "Fitting on params - 2000 0.5 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 4\n",
            "Fitting on params - 2000 0.5 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 5\n",
            "Fitting on params - 2000 0.5 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 10\n",
            "Fitting on params - 2000 0.5 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 20\n",
            "Fitting on params - 2000 0.5 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  2000 0.5 50\n",
            "Fitting on params - 2000 1 1.0\n",
            "Fitting on params - 2000 1 2\n",
            "Fitting on params - 2000 1 3\n",
            "Fitting on params - 2000 1 4\n",
            "Fitting on params - 2000 1 5\n",
            "Fitting on params - 2000 1 10\n",
            "Fitting on params - 2000 1 20\n",
            "Fitting on params - 2000 1 50\n",
            "Fitting on params - 2000 2 2\n",
            "Fitting on params - 2000 2 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting on params - 2000 2 4\n",
            "Fitting on params - 2000 2 5\n",
            "Fitting on params - 2000 2 10\n",
            "Fitting on params - 2000 2 20\n",
            "Fitting on params - 2000 2 50\n",
            "Fitting on params - 2000 3 3\n",
            "Fitting on params - 2000 3 4\n",
            "Fitting on params - 2000 3 5\n",
            "Fitting on params - 2000 3 10\n",
            "Fitting on params - 2000 3 20\n",
            "Fitting on params - 2000 3 50\n",
            "Fitting on params - 2000 5 5\n",
            "Fitting on params - 2000 5 10\n",
            "Fitting on params - 2000 5 20\n",
            "Fitting on params - 2000 5 50\n",
            "Fitting on params - 2000 10 10\n",
            "Fitting on params - 2000 10 20\n",
            "Fitting on params - 2000 10 50\n",
            "Fitting on params - 10000 0.3 0.3\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.3 0.3\n",
            "Fitting on params - 10000 0.3 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.3 0.4\n",
            "Fitting on params - 10000 0.3 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.3 0.5\n",
            "Fitting on params - 10000 0.3 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.3 1.0\n",
            "Fitting on params - 10000 0.3 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 2\n",
            "Fitting on params - 10000 0.3 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 3\n",
            "Fitting on params - 10000 0.3 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 4\n",
            "Fitting on params - 10000 0.3 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 5\n",
            "Fitting on params - 10000 0.3 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 10\n",
            "Fitting on params - 10000 0.3 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 20\n",
            "Fitting on params - 10000 0.3 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.3 50\n",
            "Fitting on params - 10000 0.4 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.4 0.4\n",
            "Fitting on params - 10000 0.4 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.4 0.5\n",
            "Fitting on params - 10000 0.4 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.4 1.0\n",
            "Fitting on params - 10000 0.4 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 2\n",
            "Fitting on params - 10000 0.4 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 3\n",
            "Fitting on params - 10000 0.4 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 4\n",
            "Fitting on params - 10000 0.4 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 5\n",
            "Fitting on params - 10000 0.4 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 10\n",
            "Fitting on params - 10000 0.4 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 20\n",
            "Fitting on params - 10000 0.4 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.4 50\n",
            "Fitting on params - 10000 0.5 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.5 0.5\n",
            "Fitting on params - 10000 0.5 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  10000 0.5 1.0\n",
            "Fitting on params - 10000 0.5 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 2\n",
            "Fitting on params - 10000 0.5 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 3\n",
            "Fitting on params - 10000 0.5 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 4\n",
            "Fitting on params - 10000 0.5 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 5\n",
            "Fitting on params - 10000 0.5 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 10\n",
            "Fitting on params - 10000 0.5 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 20\n",
            "Fitting on params - 10000 0.5 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  10000 0.5 50\n",
            "Fitting on params - 10000 1 1.0\n",
            "Fitting on params - 10000 1 2\n",
            "Fitting on params - 10000 1 3\n",
            "Fitting on params - 10000 1 4\n",
            "Fitting on params - 10000 1 5\n",
            "Fitting on params - 10000 1 10\n",
            "Fitting on params - 10000 1 20\n",
            "Fitting on params - 10000 1 50\n",
            "Fitting on params - 10000 2 2\n",
            "Fitting on params - 10000 2 3\n",
            "Fitting on params - 10000 2 4\n",
            "Fitting on params - 10000 2 5\n",
            "Fitting on params - 10000 2 10\n",
            "Fitting on params - 10000 2 20\n",
            "Fitting on params - 10000 2 50\n",
            "Fitting on params - 10000 3 3\n",
            "Fitting on params - 10000 3 4\n",
            "Fitting on params - 10000 3 5\n",
            "Fitting on params - 10000 3 10\n",
            "Fitting on params - 10000 3 20\n",
            "Fitting on params - 10000 3 50\n",
            "Fitting on params - 10000 5 5\n",
            "Fitting on params - 10000 5 10\n",
            "Fitting on params - 10000 5 20\n",
            "Fitting on params - 10000 5 50\n",
            "Fitting on params - 10000 10 10\n",
            "Fitting on params - 10000 10 20\n",
            "Fitting on params - 10000 10 50\n",
            "Fitting on params - None 0.3 0.3\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.3 0.3\n",
            "Fitting on params - None 0.3 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.3 0.4\n",
            "Fitting on params - None 0.3 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.3 0.5\n",
            "Fitting on params - None 0.3 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.3 1.0\n",
            "Fitting on params - None 0.3 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 2\n",
            "Fitting on params - None 0.3 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 3\n",
            "Fitting on params - None 0.3 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 4\n",
            "Fitting on params - None 0.3 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 5\n",
            "Fitting on params - None 0.3 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 10\n",
            "Fitting on params - None 0.3 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 20\n",
            "Fitting on params - None 0.3 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.3 50\n",
            "Fitting on params - None 0.4 0.4\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.4 0.4\n",
            "Fitting on params - None 0.4 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.4 0.5\n",
            "Fitting on params - None 0.4 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.4 1.0\n",
            "Fitting on params - None 0.4 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 2\n",
            "Fitting on params - None 0.4 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 3\n",
            "Fitting on params - None 0.4 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 4\n",
            "Fitting on params - None 0.4 5\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 5\n",
            "Fitting on params - None 0.4 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 10\n",
            "Fitting on params - None 0.4 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 20\n",
            "Fitting on params - None 0.4 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.4 50\n",
            "Fitting on params - None 0.5 0.5\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.5 0.5\n",
            "Fitting on params - None 0.5 1.0\n",
            "Exception - After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "Params -  None 0.5 1.0\n",
            "Fitting on params - None 0.5 2\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 2\n",
            "Fitting on params - None 0.5 3\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 3\n",
            "Fitting on params - None 0.5 4\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 4\n",
            "Fitting on params - None 0.5 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 5\n",
            "Fitting on params - None 0.5 10\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 10\n",
            "Fitting on params - None 0.5 20\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 20\n",
            "Fitting on params - None 0.5 50\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  None 0.5 50\n",
            "Fitting on params - None 1 1.0\n",
            "Fitting on params - None 1 2\n",
            "Fitting on params - None 1 3\n",
            "Fitting on params - None 1 4\n",
            "Fitting on params - None 1 5\n",
            "Fitting on params - None 1 10\n",
            "Fitting on params - None 1 20\n",
            "Fitting on params - None 1 50\n",
            "Fitting on params - None 2 2\n",
            "Fitting on params - None 2 3\n",
            "Fitting on params - None 2 4\n",
            "Fitting on params - None 2 5\n",
            "Fitting on params - None 2 10\n",
            "Fitting on params - None 2 20\n",
            "Fitting on params - None 2 50\n",
            "Fitting on params - None 3 3\n",
            "Fitting on params - None 3 4\n",
            "Fitting on params - None 3 5\n",
            "Fitting on params - None 3 10\n",
            "Fitting on params - None 3 20\n",
            "Fitting on params - None 3 50\n",
            "Fitting on params - None 5 5\n",
            "Fitting on params - None 5 10\n",
            "Fitting on params - None 5 20\n",
            "Fitting on params - None 5 50\n",
            "Fitting on params - None 10 10\n",
            "Fitting on params - None 10 20\n",
            "Fitting on params - None 10 50\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "# Setting optional params we will try\n",
        "max_features = [\n",
        "                500, \n",
        "                2000, \n",
        "                10000, \n",
        "                None  # default\n",
        "                ]\n",
        "min_df = [\n",
        "          0.3,\n",
        "          0.4,\n",
        "          0.5,\n",
        "          1,  # default\n",
        "          2,\n",
        "          3,\n",
        "          5,\n",
        "          10\n",
        "         ]\n",
        "max_df = [0.3,\n",
        "          0.4,\n",
        "          0.5,\n",
        "          1.0, # default\n",
        "          2,\n",
        "          3,\n",
        "          5,\n",
        "          10,\n",
        "          20,\n",
        "          50,          \n",
        "         ] \n",
        "\n",
        "\n",
        "# Saving the performance and params results here\n",
        "results = []\n",
        "\n",
        "# Creating all the optional combinations of params\n",
        "params = list(itertools.product(max_features, min_df, max_df))\n",
        "params = [(mf, mind, maxd) for (mf, mind, maxd) in params if mind <= maxd]\n",
        "\n",
        "\n",
        "for mf, mind, maxd in params:\n",
        "    print(\"Fitting on params -\", mf, mind, maxd)\n",
        "    \n",
        "    cv = CountVectorizer(stop_words='english', max_features=mf, min_df=mind, max_df=maxd)\n",
        "\n",
        "    try:\n",
        "        optcvectorizer = cv.fit(data_train)\n",
        "        train_vectorized_ds = optcvectorizer.transform(data_train)\n",
        "        test_vectorized_ds = optcvectorizer.transform(data_test)\n",
        "        \n",
        "        mnb = MultinomialNB().fit(train_vectorized_ds, labels_train)\n",
        "        test_preds = mnb.predict(test_vectorized_ds)\n",
        "        accuracy = accuracy_score(y_pred=test_preds, y_true=labels_test)\n",
        "        results.append((mf, mind, maxd, accuracy))\n",
        "    except Exception as e:\n",
        "        # In case a parameters combination is invalid print it and continue\n",
        "        print(\"Exception - \" + str(e))\n",
        "        print(\"Params - \", mf, mind, maxd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>max_features</th>\n",
              "      <th>min_df</th>\n",
              "      <th>max_df</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.862206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.851335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.845236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.835867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.818101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.817748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.810235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.806435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.794237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.793000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     max_features  min_df  max_df  accuracy\n",
              "91            NaN       1    50.0  0.862206\n",
              "90            NaN       1    20.0  0.851335\n",
              "89            NaN       1    10.0  0.845236\n",
              "98            NaN       2    50.0  0.835867\n",
              "104           NaN       3    50.0  0.818101\n",
              "84            NaN       1     1.0  0.817748\n",
              "88            NaN       1     5.0  0.810235\n",
              "97            NaN       2    20.0  0.806435\n",
              "87            NaN       1     4.0  0.794237\n",
              "108           NaN       5    50.0  0.793000"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res_df = pd.DataFrame(results, columns=['max_features', 'min_df', 'max_df', 'accuracy'])\n",
        "res_df.sort_values('accuracy', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that the main param that has impact here is the max_df for high values (seems like it's cleaning noise).\n",
        "\n",
        "Let's try to optimize it with some additional values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting with max_df: 0\n",
            "Exception - max_df corresponds to < documents than min_df\n",
            "Params -  0\n",
            "Fitting with max_df: 10\n",
            "Fitting with max_df: 20\n",
            "Fitting with max_df: 30\n",
            "Fitting with max_df: 40\n",
            "Fitting with max_df: 50\n",
            "Fitting with max_df: 60\n",
            "Fitting with max_df: 70\n",
            "Fitting with max_df: 80\n",
            "Fitting with max_df: 90\n",
            "Fitting with max_df: 100\n"
          ]
        }
      ],
      "source": [
        "results2 = []\n",
        "\n",
        "for maxdf in range(0,101, 10):\n",
        "    print(\"Fitting with max_df:\", maxdf)\n",
        "    \n",
        "    cv = CountVectorizer(stop_words='english', max_df=maxdf)\n",
        "\n",
        "    try:\n",
        "        optcvectorizer = cv.fit(data_train)\n",
        "        train_vectorized_ds = optcvectorizer.transform(data_train)\n",
        "        test_vectorized_ds = optcvectorizer.transform(data_test)\n",
        "        \n",
        "        mnb = MultinomialNB().fit(train_vectorized_ds, labels_train)\n",
        "        test_preds = mnb.predict(test_vectorized_ds)\n",
        "        accuracy = accuracy_score(y_pred=test_preds, y_true=labels_test)\n",
        "        results2.append((maxdf, accuracy))\n",
        "    except Exception as e:\n",
        "        # In case a parameters combination is invalid print it and continue\n",
        "        print(\"Exception - \" + str(e))\n",
        "        print(\"Params - \", maxdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>max_df</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>0.862206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>0.860262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60</td>\n",
              "      <td>0.859024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>70</td>\n",
              "      <td>0.857168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>80</td>\n",
              "      <td>0.856373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100</td>\n",
              "      <td>0.856284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>0.856196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>90</td>\n",
              "      <td>0.856196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>0.851335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0.845236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   max_df  accuracy\n",
              "4      50  0.862206\n",
              "3      40  0.860262\n",
              "5      60  0.859024\n",
              "6      70  0.857168\n",
              "7      80  0.856373\n",
              "9     100  0.856284\n",
              "2      30  0.856196\n",
              "8      90  0.856196\n",
              "1      20  0.851335\n",
              "0      10  0.845236"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res_df2 = pd.DataFrame(results2, columns=['max_df', 'accuracy'])\n",
        "res_df2.sort_values('accuracy', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seems like the best value is somewhere between 40-60, I would stick with 50 in order to avoid overfitting to a specific value based on our set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previous accuracy was 81.77% with the default params, let's check the new test performance with the optimized params:\n",
        "\n",
        "- max_df = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.83      0.89       480\n",
            "           1       0.84      0.87      0.86       584\n",
            "           2       0.97      0.31      0.47       591\n",
            "           3       0.78      0.87      0.82       590\n",
            "           4       0.92      0.88      0.90       578\n",
            "           5       0.82      0.93      0.87       593\n",
            "           6       0.90      0.88      0.89       585\n",
            "           7       0.94      0.87      0.90       594\n",
            "           8       0.94      0.90      0.92       598\n",
            "           9       0.96      0.89      0.92       597\n",
            "          10       0.54      0.95      0.69       600\n",
            "          11       0.89      0.91      0.90       595\n",
            "          12       0.92      0.88      0.90       591\n",
            "          13       0.90      0.94      0.92       594\n",
            "          14       0.90      0.91      0.91       593\n",
            "          15       0.85      0.95      0.90       599\n",
            "          16       0.92      0.90      0.91       546\n",
            "          17       0.87      0.92      0.90       564\n",
            "          18       0.93      0.90      0.91       465\n",
            "          19       0.95      0.69      0.80       377\n",
            "\n",
            "    accuracy                           0.86     11314\n",
            "   macro avg       0.89      0.86      0.86     11314\n",
            "weighted avg       0.88      0.86      0.86     11314\n",
            "\n",
            "\n",
            "Accuracy: 0.8622061163160686\n"
          ]
        }
      ],
      "source": [
        "cv2 = CountVectorizer(stop_words='english', max_df=50)\n",
        "cv2.fit(data_train)\n",
        "train_ds_opt = cv2.transform(data_train)\n",
        "test_ds_opt = cv2.transform(data_test)\n",
        "\n",
        "mnb2 = MultinomialNB().fit(train_ds_opt, labels_train)\n",
        "test_preds_opt = mnb2.predict(test_ds_opt)\n",
        "accuracy = accuracy_score(y_pred=test_preds_opt, y_true=labels_test)\n",
        "print(classification_report(y_pred=test_preds_opt, y_true=labels_test))\n",
        "print(\"\\nAccuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We improved from 81.77% accuracy to 86.22% accuracy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional: Model interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WrTOhkHV9msW",
        "outputId": "c69cb41c-5ed6-4e43-ef3f-6ccaa4980c1d"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def print_txt(txt, hot, cold):\n",
        "  \"\"\"\n",
        "  print the text, coloring hot and cold words with colors\n",
        "  \"\"\"\n",
        "  cold_color='\\x1b[41;37m{}\\x1b[0m'\n",
        "  hot_color='\\x1b[42;37m{}\\x1b[0m'\n",
        "  def color(token):\n",
        "    lower = str(token).lower()\n",
        "    lower = lower.replace('\\t','').replace('\\n','')\n",
        "    lower = lower.translate(string.punctuation)\n",
        "    if (lower in hot) and (lower in cold):\n",
        "      return mid_color.format(token)\n",
        "    elif lower in hot:\n",
        "      return hot_color.format(token)\n",
        "    elif lower in cold:\n",
        "      return cold_color.format(token)\n",
        "    else:\n",
        "      return token\n",
        "  colored_txt = \" \".join([color(token) for token in txt.split(' ')])\n",
        "  print(colored_txt)\n",
        "print_txt('This word support the first class but this the other', ['word'],['other'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did not have time to get to it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Thank you!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NB exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
