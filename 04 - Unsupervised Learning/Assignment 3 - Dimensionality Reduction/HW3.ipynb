{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality reduction"
      ],
      "metadata": {
        "id": "yCGQrsG-NUqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this task you will practice dimensionality reduction.\n",
        "Use code cells to answer the Tasks and Markdown cells for the Questions (Q's)."
      ],
      "metadata": {
        "id": "7S1fLhWrNUqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "0WunJoeBNUqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "wDU0D_i4NUqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y) = load_wine(return_X_y=True)\n",
        "\n",
        "# split X into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0,stratify=y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "gz0rJb-RNUqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take a quick look at the data:\r\n",
        "\r\n",
        "You can see details and metadata here, including the meaning of features:\r\n",
        "https://scikit-learn.org/stable/datasets/index.html#wine-dataset"
      ],
      "metadata": {
        "id": "Wj1Qmk5TNUqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train).describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "N4mmBloLNUqs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "r5a_r0IAN28_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement: if you perform PCA and maintain all of the principal components, no data is discarded and you did not perform dimensionality reduction.\n",
        "\n",
        "**Q1 (_max score - 10 points_)** : Do you agree? Explain your answer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\r\n"
      ],
      "metadata": {
        "id": "JfcbR21OOctW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA + Random forest"
      ],
      "metadata": {
        "id": "Fz61Bry_NUqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1 (_max score - 10 points_)**: Use X_train, y_train to train a random forest with the deafult parameters. You can read more about the algorithm in SKlearn's documentation.\n",
        "Evaulate the algorithm using accuracy score and X_test, y_test."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "2n2dLYs7OamM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 (_max score - 10 points_)**: Now do the same, but use PCA.\n",
        "\n",
        "You are asked to use the **maximal number** of componenets for PCA.\n",
        "Print the accuracy of Random forest + PCA.\n",
        "\n",
        "Remeber, you should center and scale your data before you apply PCA."
      ],
      "metadata": {
        "id": "xdMTkzsaNUqu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "eJsfOOsbPLKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2 (_max score - 5 points_)**: By applying PCA, did random forest's results improved\\stayed the same\\got worse? "
      ],
      "metadata": {
        "id": "PxJzGq8jNUqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "7_takc1QPqJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA + logistic regression"
      ],
      "metadata": {
        "id": "SYrmAR9_NUqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3 (_max score - 5 points_)**: repeat task 1 with logistic regression."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "VfxnEWAIQEhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4 (_max score - 5 points_)**: repeast task 2 with logistic regression."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "CuG83_X3QJLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3 (_max score - 5 points_)**: By applying PCA, Did linear regression results improved\\stayed the same\\got worse?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "ZxjPDCFIQ7DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4 (_max score - 10 points)**: Explain the differences between answers to Q2 and Q3. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "CnJ2GYtJRDd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5 (_max score - 20 points_)** Finding the optimal number of components:\n",
        "\n",
        "Your team decided that you must compress the data and PCA was selected. However, you are not sure how many principal components to have. Implemented the following techniques (should work without human intervention):\n",
        "\n",
        "1. Keeping at least 50% of the variance with minimum number of components\n",
        "2. Keeping above average components only\n",
        "3. The number of componets which maximize the accuracy of Logistic regression on the test set. Components which improve the accuracy by less than 0.001 are not considered as contributing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eigenfaces\r\n",
        "\r\n",
        "The approach of using eigenfaces for recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. The eigenfaces themselves form a basis set of all images used to construct the covariance matrix. Wikipedia: https://en.wikipedia.org/wiki/Eigenface\r\n",
        "\r\n",
        "The following code illustrates what each eigenface stands for. Follow the code and the comments:"
      ],
      "metadata": {
        "id": "tM_yHeDmkBRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Download the data, if not already on disk and load it as numpy arrays\n",
        "\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "# introspect the images arrays to find the shapes (for plotting)\n",
        "n_samples, h, w = lfw_people.images.shape\n",
        "\n",
        "# for machine learning we use the 2 data directly (as relative pixel\n",
        "# positions info is ignored by this model)\n",
        "X = lfw_people.data\n",
        "n_features = X.shape[1]\n",
        "\n",
        "print(\"Total dataset size:\")\n",
        "print(\"n_samples: %d\" % n_samples)\n",
        "print(\"n_features: %d\" % n_features)\n",
        "\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
        "# dataset): unsupervised feature extraction / dimensionality reduction\n",
        "n_components = 150\n",
        "\n",
        "print(\"Extracting the top %d eigenfaces from %d faces\" % (n_components, X.shape[0]))\n",
        "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
        "          whiten=True).fit(X)\n",
        "\n",
        "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
        "\n",
        "# Helper function\n",
        "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
        "        plt.title(titles[i], size=12)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "\n",
        "#############################################################################\n",
        "# plot the gallery of the most significative eigenfaces\n",
        "eigenface_titles = [\"eigenface {} - {:3.2f}% var\".format(i, pca.explained_variance_ratio_[i]) for i in range(eigenfaces.shape[0])]\n",
        "plot_gallery(eigenfaces, eigenface_titles, h, w, n_row=5, n_col=5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "4SF1qPL7kDf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6 (_max score - 20 points_)**: Plot the reconstruction of an image with different number of principal components used (1 to 30 components). However, for effiency, you are not allowed to refit the PCA object.\n",
        "\n",
        "The resulting plot will allow us to understand the contribution of each principal component.\n",
        "Check the result for different images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# For a specific image, see how adding PCs affect the reconstruction\r\n",
        "pic = X[300] # choose any arbitrary image\r\n",
        "numPCs = 30\r\n",
        "\r\n",
        "plt.figure(figsize=(20,10))\r\n",
        "plt.figure(figsize=(1.8 * numPCs/5, 2.4 * 5))\r\n",
        "for i in range(1, numPCs+1):\r\n",
        "  ### Take the first i principal components\r\n",
        "  # Your code here\r\n",
        "\r\n",
        "  ### Reduce the dimensionality of the image\r\n",
        "  # Your code here\r\n",
        "\r\n",
        "  ### Reconstruct the image to the original dimension\r\n",
        "  # Your code here\r\n",
        "\r\n",
        "  ### Plot the image\r\n",
        "\r\n",
        "  # You are not allowed to refit the pca object\r\n",
        "  # Hint: take a look at sklearn's PCA transform and inverse_transform implementation\r\n",
        "  \r\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "u0OjtkUPADhb"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3.ipynb",
      "provenance": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}